# 微积分
# 解释导数
import torch
from torch.distributions import multinomial

# 2.6 概率论
# 为了抽取一个样本，即掷骰子，我们只需要输入一个概率向量，输出是另一个相同长度的向量，它在索引i处的值是采样结果中i出现的次数；
fair_probs = torch.ones([6]) / 6
print(fair_probs)
# tensor([0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667])

# 1次掷骰子，1次采样
print(multinomial.Multinomial(1, fair_probs).sample())
# tensor([0., 0., 1., 0., 0., 0.])

# 10次掷骰子，10次采样
print(multinomial.Multinomial(10, fair_probs).sample())
# tensor([4., 1., 1., 0., 2., 2.])

# 1000次掷骰子，1000次采样
# 我们统计1000次投掷后每个数字被投中次数。我们计算相对概率，用于对真实概率的估计
counts = multinomial.Multinomial(1000, fair_probs).sample()
print(counts / 1000)  # 相对概率用作估计
# tensor([0.1580, 0.1710, 0.1860, 0.1550, 0.1720, 0.1580])

# 掷10次骰子为一组，进行500组实验
print("\n\n=== 掷10次骰子为一组，进行500组实验")

counts = multinomial.Multinomial(10, fair_probs).sample((500,))
print(counts)
# tensor([[3., 3., 1., 1., 1., 1.],
#         [3., 2., 1., 2., 0., 2.],
#         [1., 1., 2., 1., 2., 3.],
#         ...,
#         [2., 3., 0., 1., 2., 2.],
#         [1., 1., 2., 5., 0., 1.],
#         [1., 1., 3., 3., 0., 2.]])

cum_counts = counts.cumsum(dim=0)
print(cum_counts)
# tensor([[  1.,   4.,   1.,   1.,   2.,   1.],
#         [  2.,   6.,   3.,   2.,   6.,   1.],
#         [  5.,   7.,   3.,   5.,   9.,   1.],
#         ...,
#         [850., 808., 839., 816., 807., 860.],
#         [851., 810., 840., 819., 810., 860.],
#         [854., 812., 840., 821., 812., 861.]])

estimates = cum_counts / cum_counts.sum(dim=1, keepdim=True)
print(estimates)
# tensor([[0.1000, 0.4000, 0.1000, 0.0000, 0.3000, 0.1000],
#         [0.1000, 0.2000, 0.2000, 0.0500, 0.2500, 0.2000],
#         [0.1000, 0.1667, 0.2333, 0.0667, 0.2667, 0.1667],
#         ...,
#         [0.1677, 0.1683, 0.1747, 0.1675, 0.1657, 0.1562],
#         [0.1675, 0.1683, 0.1745, 0.1677, 0.1655, 0.1563],
#         [0.1672, 0.1682, 0.1748, 0.1678, 0.1656, 0.1564]])


